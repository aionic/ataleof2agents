# Agent Framework Tutorial

Learn how to build AI agents with external API integration using Microsoft Agent Framework.

---

## What is Agent Framework?

**Agent Framework** is Microsoft's framework for building AI agents that can:
- Execute multi-step workflows
- Call external APIs and tools
- Make decisions based on context
- Provide conversational experiences

**Key Difference from Direct LLM Calls**:
```python
# Direct LLM (limited)
response = openai.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "What's the weather?"}]
)
# âŒ Can't actually get weather - just guesses

# Agent Framework (powerful)
agent = Agent(tools=[weather_api_tool])
response = agent.run("What's the weather in 10001?")
# âœ… Actually calls weather API, gets real data
```

---

## Core Concepts

### 1. Agents

An **agent** is an AI assistant with:
- **Instructions**: System prompt defining behavior
- **Model**: LLM to use (GPT-4, GPT-3.5, etc.)
- **Tools**: External APIs/functions it can call
- **Workflow**: Steps to execute

**Example Configuration** (`agent.yaml`):
```yaml
name: WeatherClothingAdvisor
model: gpt-4
instructions: |
  You are a clothing advisor.
  Use weather data to recommend appropriate clothing.
tools:
  - type: openapi
    name: get_weather
    spec: weather-api.json
```

### 2. Tools

**Tools** are external capabilities agents can use:
- **OpenAPI Tools**: HTTP APIs defined by OpenAPI spec
- **Function Tools**: Python/Node.js functions
- **Code Interpreter**: Execute code
- **File Search**: Search documents

**This repo focuses on OpenAPI tools** (most portable).

### 3. Workflows

**Workflows** orchestrate multiple steps:
```
Step 1: Parse user input
Step 2: Call external API
Step 3: Process data
Step 4: Generate response
```

**Agent Framework provides**:
- **Sequential**: Steps run one after another
- **Concurrent**: Steps run in parallel
- **Conditional**: Steps run based on logic

### 4. Portability

**Same agent code works everywhere**:
- Azure Container Apps (self-hosted)
- Azure AI Foundry (managed)
- Local development
- Other cloud providers

**Why**: Standard patterns (HTTP APIs, YAML config, Python code)

---

## Building Your First Agent

### Step 1: Define the Problem

**Example**: Weather-based clothing advisor

**Requirements**:
1. User provides location (zip code)
2. Get current weather data
3. Recommend appropriate clothing
4. Conversational response

### Step 2: Design the Workflow

```
User Input â†’ Parse Zip Code â†’ Get Weather â†’ Analyze â†’ Recommend Clothing
```

**Key Decision**: Is the weather API part of the agent, or external?

**Answer**: **External** (better for portability)

### Step 3: Create External API

**Option A**: Use existing weather API
**Option B**: Create wrapper API

**This repo uses Option B** (Container Apps weather API):

```python
# weather_service.py
@app.get("/api/weather")
async def get_weather(zip_code: str):
    # Call OpenWeatherMap
    data = fetch_from_openweathermap(zip_code)

    # Return standardized format
    return {
        "location": data["name"],
        "temperature": data["main"]["temp"],
        "condition": data["weather"][0]["main"],
        "description": data["weather"][0]["description"]
    }
```

**Why a wrapper?**
- Standardized output format
- Authentication handling
- Error normalization
- Caching potential

### Step 4: Create OpenAPI Specification

**File**: `weather-api/openapi.json`

```json
{
  "openapi": "3.0.0",
  "info": {
    "title": "Weather API",
    "version": "1.0.0"
  },
  "servers": [
    {
      "url": "https://your-api.azurecontainerapps.io"
    }
  ],
  "paths": {
    "/api/weather": {
      "get": {
        "operationId": "getWeather",
        "summary": "Get current weather for zip code",
        "parameters": [
          {
            "name": "zip_code",
            "in": "query",
            "required": true,
            "schema": {"type": "string"},
            "description": "US zip code"
          }
        ],
        "responses": {
          "200": {
            "description": "Weather data",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "location": {"type": "string"},
                    "temperature": {"type": "number"},
                    "condition": {"type": "string"},
                    "description": {"type": "string"}
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}
```

**Critical**: Complete, valid OpenAPI 3.0 spec required.

### Step 5: Configure Agent

**File**: `agent.yaml`

```yaml
name: WeatherClothingAdvisor
description: Provides clothing recommendations based on weather

model:
  provider: azure_openai
  model_name: gpt-4
  endpoint: ${AZURE_OPENAI_ENDPOINT}
  api_key: ${AZURE_OPENAI_API_KEY}
  deployment_name: ${AZURE_OPENAI_DEPLOYMENT_NAME}

instructions: |
  You are a helpful clothing advisor.

  When user provides a location:
  1. Use get_weather tool to retrieve current weather
  2. Analyze temperature, conditions, precipitation, wind
  3. Recommend appropriate clothing items
  4. Provide conversational, helpful response

  Be specific about clothing types (e.g., "heavy winter coat" not just "coat").
  Consider layering for temperature transitions.

tools:
  - type: openapi
    openapi:
      name: get_weather
      description: Get current weather for US zip code
      spec_file: ../weather-api/openapi.json
      auth:
        type: anonymous  # Public endpoint
```

### Step 6: Implement Workflow Orchestrator

**File**: `workflow_orchestrator.py`

```python
from typing import Dict, Any
import requests
import os
from azure.ai.inference import ChatCompletionsClient
from azure.core.credentials import AzureKeyCredential

class WorkflowOrchestrator:
    """Orchestrates agent workflow with external API calls."""

    def __init__(self):
        self.weather_api_url = os.getenv("WEATHER_API_URL")
        self.openai_client = ChatCompletionsClient(
            endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            credential=AzureKeyCredential(os.getenv("AZURE_OPENAI_API_KEY"))
        )
        self.deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")

    def run(self, user_message: str) -> Dict[str, Any]:
        """Execute complete workflow."""

        # Step 1: Parse input
        zip_code = self._extract_zip_code(user_message)

        # Step 2: Get weather data
        weather = self._get_weather(zip_code)

        # Step 3: Generate recommendations
        recommendations = self._generate_recommendations(
            user_message, weather
        )

        # Step 4: Format response
        return {
            "response": recommendations,
            "metadata": {
                "zip_code": zip_code,
                "weather": weather
            }
        }

    def _extract_zip_code(self, message: str) -> str:
        """Extract zip code from user message."""
        import re
        # Look for 5-digit number
        match = re.search(r'\b\d{5}\b', message)
        if match:
            return match.group()
        raise ValueError("No zip code found in message")

    def _get_weather(self, zip_code: str) -> Dict[str, Any]:
        """Call external weather API."""
        url = f"{self.weather_api_url}/api/weather"
        response = requests.get(url, params={"zip_code": zip_code})
        response.raise_for_status()
        return response.json()

    def _generate_recommendations(
        self,
        user_message: str,
        weather: Dict[str, Any]
    ) -> str:
        """Use AI to generate clothing recommendations."""

        # Build context for AI
        context = f"""
Current weather in {weather['location']}:
- Temperature: {weather['temperature']}Â°F
- Condition: {weather['condition']}
- Description: {weather['description']}

User request: {user_message}

Provide specific clothing recommendations based on this weather.
"""

        # Call Azure OpenAI
        response = self.openai_client.complete(
            messages=[
                {"role": "system", "content": "You are a clothing advisor."},
                {"role": "user", "content": context}
            ],
            model=self.deployment_name,
            temperature=0.7
        )

        return response.choices[0].message.content
```

**Key Pattern**: Workflow orchestrator coordinates everything:
1. External API calls (weather)
2. AI reasoning (OpenAI)
3. Business logic (parsing, formatting)

### Step 7: Create FastAPI Endpoint

**File**: `app.py`

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from workflow_orchestrator import WorkflowOrchestrator

app = FastAPI()
orchestrator = WorkflowOrchestrator()

class ChatRequest(BaseModel):
    message: str
    session_id: str = None

@app.post("/chat")
async def chat(request: ChatRequest):
    """Agent conversation endpoint."""
    try:
        result = orchestrator.run(request.message)
        return {
            "response": result["response"],
            "session_id": request.session_id or "default",
            "metadata": result["metadata"]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health():
    return {"status": "healthy"}
```

---

## External API Integration Patterns

### Pattern 1: Direct HTTP Calls (This Repo)

**Agent â†’ External API â†’ Response**

```python
# In workflow orchestrator
weather = requests.get(f"{api_url}/weather", params={"zip": zip_code})
```

**Pros**:
- âœ… Simple
- âœ… Portable
- âœ… Fast
- âœ… Easy to test

**Cons**:
- âŒ Manual error handling
- âŒ No automatic retries
- âŒ Must manage auth

### Pattern 2: OpenAPI Tools (Foundry)

**Agent â†’ Foundry Runtime â†’ External API â†’ Response**

```yaml
# Agent tells Foundry about API
tools:
  - type: openapi
    spec: api-spec.json
```

**Pros**:
- âœ… Automatic invocation
- âœ… Built-in retries
- âœ… Portal visibility

**Cons**:
- âŒ Slower (overhead)
- âŒ Foundry-specific
- âŒ Less control

### Pattern 3: Hybrid (Best of Both)

**Use Case 1 (Simple)**: Direct API + business logic
**Use Case 2 (Complex)**: Agent reasoning

```python
def handle_request(message: str):
    weather = get_weather_api(extract_zip(message))

    if is_simple_case(weather):
        # Pattern 1: Business logic only
        return apply_simple_rules(weather)
    else:
        # Pattern 2: Agent reasoning
        return agent.analyze(weather)
```

**Result**: 70% cost reduction (use expensive AI only when needed)

---

## Deployment Models

### Container Apps (Self-Hosted)

**What you manage**:
- Docker containers
- Infrastructure
- Scaling
- Monitoring

**What you get**:
- Full control
- Faster responses (2.3x)
- Lower cost at scale
- Standard containers

**Code**: See `src/agent-container/`

### Azure AI Foundry (Managed)

**What Microsoft manages**:
- Agent runtime
- Infrastructure
- Scaling
- Built-in features

**What you get**:
- No containers
- Rapid deployment
- Portal UI
- Conversation management

**Code**: See `src/agent-foundry/`

### Code Comparison

**Container Apps** (`workflow_orchestrator.py`):
```python
# Direct control over everything
class WorkflowOrchestrator:
    def run(self, message: str):
        # You orchestrate each step
        zip_code = parse_input(message)
        weather = call_api(zip_code)
        response = generate(weather)
        return response
```

**Foundry** (`register_agent.py`):
```python
# Foundry manages orchestration
agent = client.agents.create_agent(
    model="gpt-4",
    instructions="...",
    tools=[openapi_tool]  # Foundry calls API automatically
)
```

**Portability**: Minimal code changes to switch between them.

---

## Best Practices

### 1. Design for Portability

âœ… **DO**: Use standard HTTP APIs
```python
weather = requests.get(f"{api_url}/weather")
```

âŒ **DON'T**: Use platform-specific features
```python
weather = foundry.special_tool.get_weather()  # Locks you in
```

### 2. Separate Concerns

âœ… **DO**: External API as separate service
```
Agent Container â†’ Weather API Container
```

âŒ **DON'T**: Embed everything in agent
```
Agent (with embedded weather code)  # Hard to port
```

### 3. Use Environment Variables

âœ… **DO**: Configuration via .env
```python
api_url = os.getenv("WEATHER_API_URL")
```

âŒ **DON'T**: Hardcode URLs
```python
api_url = "https://specific-instance.com"  # Breaks in other envs
```

### 4. Implement Error Handling

```python
def get_weather(zip_code: str):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        return response.json()
    except requests.Timeout:
        return {"error": "Weather service timeout"}
    except requests.HTTPError as e:
        return {"error": f"Weather service error: {e.response.status_code}"}
```

### 5. Add Telemetry

```python
from opencensus.ext.azure.log_exporter import AzureLogHandler

logger = logging.getLogger(__name__)
logger.addHandler(AzureLogHandler(
    connection_string=os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING")
))

# Log workflow steps
logger.info("Workflow started", extra={"zip_code": zip_code})
logger.info("Weather retrieved", extra={"temp": weather["temperature"]})
logger.info("Workflow completed", extra={"duration": duration})
```

### 6. Cost Optimization

```python
def should_use_agent(weather: Dict) -> bool:
    """Decide if AI reasoning needed."""
    # Simple cases: use business logic (cheap)
    if is_clear_recommendation(weather):
        return False

    # Complex cases: use AI (expensive but worth it)
    return True

# In workflow
if should_use_agent(weather):
    response = agent.analyze(weather)  # Expensive
else:
    response = simple_rules(weather)   # Cheap
```

**Impact**: 70% cost reduction while maintaining quality.

---

## Code References

### Agent Container Implementation
- **Agent config**: `src/agent-container/agent.yaml`
- **Workflow config**: `src/agent-container/workflow.yaml`
- **Orchestrator**: `src/agent-container/workflow_orchestrator.py`
- **FastAPI app**: `src/agent-container/app.py`
- **Telemetry**: `src/agent-container/telemetry.py`

### Foundry Implementation
- **Agent config**: `src/agent-foundry/agent.yaml`
- **Registration**: `src/agent-foundry/register_agent.py`
- **Testing**: `src/agent-foundry/test_agent.py`

### Weather API
- **FastAPI app**: Weather API service (separate container)
- **OpenAPI spec**: `weather-api/openapi.json`

### Shared Business Logic
- **Models**: `src/shared/models.py`
- **Clothing logic**: `src/shared/clothing_logic.py`
- **Constants**: `src/shared/constants.py`

---

## Testing Your Agent

### Local Testing

```python
# test_agent_local.py
from workflow_orchestrator import WorkflowOrchestrator

orchestrator = WorkflowOrchestrator()

# Test case 1: Cold weather
result = orchestrator.run("What should I wear in 10001?")
assert "coat" in result["response"].lower()

# Test case 2: Invalid input
try:
    orchestrator.run("What should I wear?")  # No zip code
    assert False, "Should have raised error"
except ValueError:
    pass  # Expected

print("âœ“ All tests passed")
```

### Integration Testing

```python
# test_agent_integration.py
import requests

# Test deployed agent
response = requests.post(
    "https://ca-weather-dev.azurecontainerapps.io/chat",
    json={"message": "What should I wear in 10001?"}
)

assert response.status_code == 200
data = response.json()
assert "response" in data
assert len(data["response"]) > 0

print("âœ“ Integration test passed")
```

### Performance Testing

```python
# test_agent_performance.py
import time

start = time.time()
result = orchestrator.run("What should I wear in 10001?")
duration = time.time() - start

print(f"Response time: {duration:.2f}s")
assert duration < 10.0, "Too slow"
```

---

## Next Steps

### Deploy Your Agent

**Container Apps**:
ðŸ‘‰ **[Container Apps Deployment Guide](./DEPLOYMENT-CONTAINER-APPS.md)**

**Azure AI Foundry**:
ðŸ‘‰ **[Foundry Deployment Guide](./DEPLOYMENT-FOUNDRY.md)**

### Port Between Platforms
ðŸ‘‰ **[Porting Guide](./PORTING-GUIDE.md)**

### Advanced Patterns
ðŸ‘‰ **[Workflow Orchestration Patterns](./WORKFLOW-ORCHESTRATION-PATTERNS.md)**

### Deep Dive
ðŸ‘‰ **[Workflow Orchestration Patterns](./WORKFLOW-ORCHESTRATION-PATTERNS.md)**

---

## Summary

**Key Takeaways**:
1. **Agent Framework** enables AI agents with external tool access
2. **External APIs** via OpenAPI specs provide portability
3. **Workflow orchestration** coordinates multiple steps
4. **Same code** works in Container Apps and Foundry
5. **Hybrid pattern** (business logic + AI) optimizes costs

**You now understand**:
- What Agent Framework is and why to use it
- How to integrate external APIs
- How to build portable agents
- When to use agents vs. business logic
- How to deploy to different platforms

**Ready to build?** Start with the [Quickstart](../QUICKSTART.md) or dive into [deployment guides](./DEPLOYMENT-CONTAINER-APPS.md).
